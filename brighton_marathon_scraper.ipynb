{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brighton Marathon Results Scraper\n",
    "\n",
    "This notebook scrapes the Brighton Marathon results from the official website, including split times for each runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Scraper import Scraper\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARATHON_URL = \"https://brighton.r.mikatiming.com/2025/\"\n",
    "RUNNING_DATA_PATH = \"data/running_data_2025.csv\"\n",
    "INDIVIDUAL_DATA_PATH = \"data/individual_running_data_2025.csv\"\n",
    "\n",
    "#MARATHON_URL = \"https://brighton.r.mikatiming.com/2024/\"\n",
    "#RUNNING_DATA_PATH = \"data/running_data_2024.csv\"\n",
    "#INDIVIDUAL_DATA_PATH = \"data/individual_running_data_2024.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_url(page: int, age: int, sex: str):\n",
    " return f\"https://brighton.r.mikatiming.com/2025/?page={page}&event=BRMA&pid=search&search%5Bage_class%5D={age}&search%5Bsex%5D={sex}&search%5Bnation%5D=%25&search_sort=name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = Scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'age' : [18, 40, 45, 50, 55, 60, 65, 70, 75],\n",
    "    'sex' : ['M', 'W', 'D']  \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Main Data and hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_pages(params: dict) -> pd.DataFrame:\n",
    "\n",
    "    params_running_data = pd.DataFrame()\n",
    "\n",
    "    page_number = 1\n",
    "    last_data_frame_size = 1\n",
    "\n",
    "    while(last_data_frame_size > 0 ):\n",
    "        page_data = scraper.scrape_runner_data(get_page_url(page_number, params['age'], params['sex']))\n",
    "        params_running_data = pd.concat([params_running_data, page_data], ignore_index=True)\n",
    "\n",
    "        page_number += 1\n",
    "        last_data_frame_size = page_data.shape[0]\n",
    "\n",
    "        if page_number % 10 == 0:\n",
    "            logging.info(f'page {page_number} scraped. Results size: {params_running_data.shape[0]}')\n",
    "\n",
    "    params_running_data['sex'] = params['sex']\n",
    "    params_running_data['age'] = params['age']\n",
    "\n",
    "    return params_running_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "running_data = pd.DataFrame()\n",
    "\n",
    "keys = search_params.keys()\n",
    "for values in product(*search_params.values()):\n",
    "    combo = dict(zip(keys, values))\n",
    "    \n",
    "    logging.info(f'scraping pages with params: {combo}')\n",
    "\n",
    "    running_data = pd.concat([running_data, scrape_all_pages(combo)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_data.to_csv(RUNNING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Individual Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_data = pd.read_csv(RUNNING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_running_data = pd.DataFrame()\n",
    "\n",
    "for index, row in running_data.iterrows():\n",
    "    ind_data = scraper.scrape_individual_data(MARATHON_URL + row['hyper_link'])\n",
    "    ind_data['bib_number'] = row['bib_number']\n",
    "\n",
    "    individual_running_data = pd.concat([individual_running_data, ind_data])\n",
    "\n",
    "    if index % 100 == 0:\n",
    "        logging.info(f'index {index} scraped. Results size: {individual_running_data.shape[0]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_running_data.to_csv(INDIVIDUAL_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
