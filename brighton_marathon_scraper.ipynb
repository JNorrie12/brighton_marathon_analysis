{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brighton Marathon Results Scraper\n",
    "\n",
    "This notebook scrapes the Brighton Marathon results from the official website, including split times for each runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Scraper import Scraper\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure the logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARATHON_URL = \"https://brighton.r.mikatiming.com/2025/\"\n",
    "#RUNNING_DATA_PATH = \"data/running_data_2025.csv\"\n",
    "#INDIVIDUAL_DATA_PATH = \"data/individual_running_data_2025.csv\"\n",
    "\n",
    "MARATHON_URL = \"https://brighton.r.mikatiming.com/2024/\"\n",
    "RUNNING_DATA_PATH = \"data/running_data_2024.csv\"\n",
    "INDIVIDUAL_DATA_PATH = \"data/individual_running_data_2024.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_url(page: int):\n",
    "    return MARATHON_URL + f\"?page={page}&event=BRMA&pid=list\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 15:26:35 - INFO - ====== WebDriver manager ======\n",
      "2025-04-13 15:26:36 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-04-13 15:26:36 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2025-04-13 15:26:37 - INFO - Driver [C:\\Users\\norri\\.wdm\\drivers\\chromedriver\\win64\\135.0.7049.84\\chromedriver-win32/chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "scraper = Scraper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Main Data and hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 15:26:47 - INFO - page 10 scraped. Results size: 225\n",
      "2025-04-13 15:26:54 - INFO - page 20 scraped. Results size: 475\n",
      "2025-04-13 15:27:02 - INFO - page 30 scraped. Results size: 725\n",
      "2025-04-13 15:27:09 - INFO - page 40 scraped. Results size: 975\n",
      "2025-04-13 15:27:18 - INFO - page 50 scraped. Results size: 1225\n",
      "2025-04-13 15:27:27 - INFO - page 60 scraped. Results size: 1475\n",
      "2025-04-13 15:27:36 - INFO - page 70 scraped. Results size: 1725\n",
      "2025-04-13 15:27:45 - INFO - page 80 scraped. Results size: 1975\n",
      "2025-04-13 15:27:54 - INFO - page 90 scraped. Results size: 2225\n",
      "2025-04-13 15:28:04 - INFO - page 100 scraped. Results size: 2475\n",
      "2025-04-13 15:28:15 - INFO - page 110 scraped. Results size: 2725\n",
      "2025-04-13 15:28:24 - INFO - page 120 scraped. Results size: 2975\n",
      "2025-04-13 15:28:32 - INFO - page 130 scraped. Results size: 3225\n",
      "2025-04-13 15:28:43 - INFO - page 140 scraped. Results size: 3475\n",
      "2025-04-13 15:28:52 - INFO - page 150 scraped. Results size: 3725\n",
      "2025-04-13 15:29:01 - INFO - page 160 scraped. Results size: 3975\n",
      "2025-04-13 15:29:10 - INFO - page 170 scraped. Results size: 4225\n",
      "2025-04-13 15:29:20 - INFO - page 180 scraped. Results size: 4475\n",
      "2025-04-13 15:29:29 - INFO - page 190 scraped. Results size: 4725\n",
      "2025-04-13 15:29:38 - INFO - page 200 scraped. Results size: 4975\n",
      "2025-04-13 15:29:47 - INFO - page 210 scraped. Results size: 5225\n",
      "2025-04-13 15:29:57 - INFO - page 220 scraped. Results size: 5475\n",
      "2025-04-13 15:30:08 - INFO - page 230 scraped. Results size: 5725\n",
      "2025-04-13 15:30:17 - INFO - page 240 scraped. Results size: 5975\n",
      "2025-04-13 15:30:27 - INFO - page 250 scraped. Results size: 6225\n",
      "2025-04-13 15:30:38 - INFO - page 260 scraped. Results size: 6475\n",
      "2025-04-13 15:30:47 - INFO - page 270 scraped. Results size: 6725\n",
      "2025-04-13 15:30:57 - INFO - page 280 scraped. Results size: 6975\n",
      "2025-04-13 15:31:09 - INFO - page 290 scraped. Results size: 7225\n",
      "2025-04-13 15:31:18 - INFO - page 300 scraped. Results size: 7475\n",
      "2025-04-13 15:31:27 - INFO - page 310 scraped. Results size: 7725\n",
      "2025-04-13 15:31:37 - INFO - page 320 scraped. Results size: 7975\n",
      "2025-04-13 15:31:46 - INFO - page 330 scraped. Results size: 8225\n",
      "2025-04-13 15:31:56 - INFO - page 340 scraped. Results size: 8475\n",
      "2025-04-13 15:32:09 - INFO - page 350 scraped. Results size: 8725\n",
      "2025-04-13 15:32:19 - INFO - page 360 scraped. Results size: 8975\n",
      "2025-04-13 15:32:28 - INFO - page 370 scraped. Results size: 9225\n",
      "2025-04-13 15:32:38 - INFO - page 380 scraped. Results size: 9475\n",
      "2025-04-13 15:32:48 - INFO - page 390 scraped. Results size: 9725\n",
      "2025-04-13 15:32:57 - INFO - page 400 scraped. Results size: 9975\n",
      "2025-04-13 15:33:07 - INFO - page 410 scraped. Results size: 10225\n",
      "2025-04-13 15:33:18 - INFO - page 420 scraped. Results size: 10475\n",
      "2025-04-13 15:33:28 - INFO - page 430 scraped. Results size: 10725\n",
      "2025-04-13 15:33:39 - INFO - page 440 scraped. Results size: 10975\n",
      "2025-04-13 15:33:48 - INFO - page 450 scraped. Results size: 11225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: scraper incompatible page for page: https://brighton.r.mikatiming.com/2024/?page=454&event=BRMA&pid=list\n"
     ]
    }
   ],
   "source": [
    "running_data = pd.DataFrame()\n",
    "\n",
    "page_number = 1\n",
    "last_data_frame_size = 1\n",
    "\n",
    "while(last_data_frame_size > 0 ):\n",
    "    page_data = scraper.scrape_runner_data(get_page_url(page_number))\n",
    "    running_data = pd.concat([running_data, page_data], ignore_index=True)\n",
    "\n",
    "    page_number += 1\n",
    "    last_data_frame_size = page_data.shape[0]\n",
    "\n",
    "    if page_number % 10 == 0:\n",
    "        logging.info(f'page {page_number} scraped. Results size: {running_data.shape[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_data.to_csv(RUNNING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Individual Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_data = pd.read_csv(RUNNING_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 15:35:50 - INFO - index 0 scraped. Results size: 10\n",
      "2025-04-13 15:36:22 - INFO - index 100 scraped. Results size: 1010\n",
      "2025-04-13 15:36:52 - INFO - index 200 scraped. Results size: 2010\n",
      "2025-04-13 15:37:24 - INFO - index 300 scraped. Results size: 3010\n",
      "2025-04-13 15:37:55 - INFO - index 400 scraped. Results size: 4010\n",
      "2025-04-13 15:38:26 - INFO - index 500 scraped. Results size: 5010\n",
      "2025-04-13 15:38:57 - INFO - index 600 scraped. Results size: 6010\n",
      "2025-04-13 15:39:31 - INFO - index 700 scraped. Results size: 7010\n",
      "2025-04-13 15:40:06 - INFO - index 800 scraped. Results size: 8010\n",
      "2025-04-13 15:40:40 - INFO - index 900 scraped. Results size: 9010\n",
      "2025-04-13 15:41:16 - INFO - index 1000 scraped. Results size: 10010\n",
      "2025-04-13 15:41:51 - INFO - index 1100 scraped. Results size: 11010\n",
      "2025-04-13 15:42:29 - INFO - index 1200 scraped. Results size: 12010\n",
      "2025-04-13 15:43:06 - INFO - index 1300 scraped. Results size: 13010\n",
      "2025-04-13 15:43:43 - INFO - index 1400 scraped. Results size: 14010\n",
      "2025-04-13 15:44:20 - INFO - index 1500 scraped. Results size: 15010\n",
      "2025-04-13 15:44:56 - INFO - index 1600 scraped. Results size: 16010\n",
      "2025-04-13 15:45:35 - INFO - index 1700 scraped. Results size: 17010\n",
      "2025-04-13 15:46:14 - INFO - index 1800 scraped. Results size: 18010\n",
      "2025-04-13 15:46:55 - INFO - index 1900 scraped. Results size: 19010\n",
      "2025-04-13 15:47:37 - INFO - index 2000 scraped. Results size: 20010\n",
      "2025-04-13 15:48:19 - INFO - index 2100 scraped. Results size: 21010\n",
      "2025-04-13 15:49:03 - INFO - index 2200 scraped. Results size: 22010\n",
      "2025-04-13 15:49:48 - INFO - index 2300 scraped. Results size: 23010\n",
      "2025-04-13 15:50:34 - INFO - index 2400 scraped. Results size: 24010\n",
      "2025-04-13 15:51:20 - INFO - index 2500 scraped. Results size: 25010\n",
      "2025-04-13 15:52:08 - INFO - index 2600 scraped. Results size: 26010\n",
      "2025-04-13 15:52:57 - INFO - index 2700 scraped. Results size: 27010\n",
      "2025-04-13 15:53:48 - INFO - index 2800 scraped. Results size: 28010\n",
      "2025-04-13 15:54:37 - INFO - index 2900 scraped. Results size: 29010\n",
      "2025-04-13 15:55:31 - INFO - index 3000 scraped. Results size: 30010\n",
      "2025-04-13 15:56:26 - INFO - index 3100 scraped. Results size: 31010\n",
      "2025-04-13 15:57:20 - INFO - index 3200 scraped. Results size: 32010\n",
      "2025-04-13 15:58:17 - INFO - index 3300 scraped. Results size: 33010\n",
      "2025-04-13 15:59:04 - INFO - index 3400 scraped. Results size: 34010\n",
      "2025-04-13 15:59:33 - INFO - index 3500 scraped. Results size: 35010\n",
      "2025-04-13 16:00:04 - INFO - index 3600 scraped. Results size: 36010\n",
      "2025-04-13 16:00:36 - INFO - index 3700 scraped. Results size: 37010\n",
      "2025-04-13 16:01:08 - INFO - index 3800 scraped. Results size: 38010\n",
      "2025-04-13 16:01:40 - INFO - index 3900 scraped. Results size: 39010\n",
      "2025-04-13 16:02:11 - INFO - index 4000 scraped. Results size: 40010\n",
      "2025-04-13 16:02:44 - INFO - index 4100 scraped. Results size: 41010\n",
      "2025-04-13 16:03:18 - INFO - index 4200 scraped. Results size: 42010\n",
      "2025-04-13 16:03:50 - INFO - index 4300 scraped. Results size: 43010\n",
      "2025-04-13 16:04:23 - INFO - index 4400 scraped. Results size: 44010\n",
      "2025-04-13 16:04:57 - INFO - index 4500 scraped. Results size: 45010\n",
      "2025-04-13 16:05:30 - INFO - index 4600 scraped. Results size: 46010\n",
      "2025-04-13 16:06:05 - INFO - index 4700 scraped. Results size: 47010\n",
      "2025-04-13 16:06:40 - INFO - index 4800 scraped. Results size: 48010\n",
      "2025-04-13 16:07:16 - INFO - index 4900 scraped. Results size: 49010\n",
      "2025-04-13 16:07:52 - INFO - index 5000 scraped. Results size: 50010\n",
      "2025-04-13 16:08:28 - INFO - index 5100 scraped. Results size: 51010\n",
      "2025-04-13 16:09:05 - INFO - index 5200 scraped. Results size: 52010\n",
      "2025-04-13 16:09:42 - INFO - index 5300 scraped. Results size: 53010\n",
      "2025-04-13 16:10:21 - INFO - index 5400 scraped. Results size: 54010\n",
      "2025-04-13 16:11:03 - INFO - index 5500 scraped. Results size: 55010\n",
      "2025-04-13 16:11:44 - INFO - index 5600 scraped. Results size: 56010\n",
      "2025-04-13 16:12:29 - INFO - index 5700 scraped. Results size: 57010\n",
      "2025-04-13 16:13:13 - INFO - index 5800 scraped. Results size: 58010\n",
      "2025-04-13 16:13:57 - INFO - index 5900 scraped. Results size: 59010\n",
      "2025-04-13 16:14:41 - INFO - index 6000 scraped. Results size: 60010\n",
      "2025-04-13 16:15:28 - INFO - index 6100 scraped. Results size: 61010\n",
      "2025-04-13 16:16:16 - INFO - index 6200 scraped. Results size: 62010\n",
      "2025-04-13 16:17:07 - INFO - index 6300 scraped. Results size: 63010\n",
      "2025-04-13 16:17:56 - INFO - index 6400 scraped. Results size: 64010\n",
      "2025-04-13 16:18:42 - INFO - index 6500 scraped. Results size: 65010\n",
      "2025-04-13 16:19:33 - INFO - index 6600 scraped. Results size: 66010\n",
      "2025-04-13 16:20:27 - INFO - index 6700 scraped. Results size: 67010\n",
      "2025-04-13 16:21:18 - INFO - index 6800 scraped. Results size: 68010\n",
      "2025-04-13 16:21:52 - INFO - index 6900 scraped. Results size: 69010\n",
      "2025-04-13 16:22:23 - INFO - index 7000 scraped. Results size: 70010\n",
      "2025-04-13 16:22:55 - INFO - index 7100 scraped. Results size: 71010\n",
      "2025-04-13 16:23:29 - INFO - index 7200 scraped. Results size: 72010\n",
      "2025-04-13 16:24:01 - INFO - index 7300 scraped. Results size: 73010\n",
      "2025-04-13 16:24:34 - INFO - index 7400 scraped. Results size: 74010\n",
      "2025-04-13 16:25:10 - INFO - index 7500 scraped. Results size: 75010\n",
      "2025-04-13 16:25:43 - INFO - index 7600 scraped. Results size: 76010\n",
      "2025-04-13 16:26:18 - INFO - index 7700 scraped. Results size: 77010\n",
      "2025-04-13 16:26:51 - INFO - index 7800 scraped. Results size: 78010\n",
      "2025-04-13 16:27:25 - INFO - index 7900 scraped. Results size: 79010\n",
      "2025-04-13 16:27:59 - INFO - index 8000 scraped. Results size: 80010\n",
      "2025-04-13 16:28:35 - INFO - index 8100 scraped. Results size: 81010\n",
      "2025-04-13 16:29:11 - INFO - index 8200 scraped. Results size: 82010\n",
      "2025-04-13 16:29:49 - INFO - index 8300 scraped. Results size: 83010\n",
      "2025-04-13 16:30:27 - INFO - index 8400 scraped. Results size: 84010\n",
      "2025-04-13 16:31:05 - INFO - index 8500 scraped. Results size: 85010\n",
      "2025-04-13 16:31:45 - INFO - index 8600 scraped. Results size: 86010\n",
      "2025-04-13 16:32:26 - INFO - index 8700 scraped. Results size: 87010\n",
      "2025-04-13 16:33:06 - INFO - index 8800 scraped. Results size: 88010\n",
      "2025-04-13 16:33:44 - INFO - index 8900 scraped. Results size: 89010\n",
      "2025-04-13 16:34:25 - INFO - index 9000 scraped. Results size: 90010\n",
      "2025-04-13 16:35:05 - INFO - index 9100 scraped. Results size: 91010\n",
      "2025-04-13 16:35:46 - INFO - index 9200 scraped. Results size: 92010\n",
      "2025-04-13 16:36:29 - INFO - index 9300 scraped. Results size: 93010\n",
      "2025-04-13 16:37:16 - INFO - index 9400 scraped. Results size: 94010\n",
      "2025-04-13 16:37:59 - INFO - index 9500 scraped. Results size: 95010\n",
      "2025-04-13 16:38:44 - INFO - index 9600 scraped. Results size: 96010\n",
      "2025-04-13 16:39:29 - INFO - index 9700 scraped. Results size: 97010\n",
      "2025-04-13 16:40:16 - INFO - index 9800 scraped. Results size: 98010\n",
      "2025-04-13 16:41:08 - INFO - index 9900 scraped. Results size: 99010\n",
      "2025-04-13 16:41:59 - INFO - index 10000 scraped. Results size: 100010\n",
      "2025-04-13 16:42:49 - INFO - index 10100 scraped. Results size: 101010\n",
      "2025-04-13 16:43:40 - INFO - index 10200 scraped. Results size: 102010\n",
      "2025-04-13 16:44:32 - INFO - index 10300 scraped. Results size: 103010\n",
      "2025-04-13 16:45:26 - INFO - index 10400 scraped. Results size: 104010\n",
      "2025-04-13 16:46:17 - INFO - index 10500 scraped. Results size: 105010\n",
      "2025-04-13 16:47:09 - INFO - index 10600 scraped. Results size: 106010\n",
      "2025-04-13 16:48:02 - INFO - index 10700 scraped. Results size: 107010\n",
      "2025-04-13 16:48:59 - INFO - index 10800 scraped. Results size: 108010\n",
      "2025-04-13 16:49:53 - INFO - index 10900 scraped. Results size: 109010\n",
      "2025-04-13 16:50:49 - INFO - index 11000 scraped. Results size: 110010\n",
      "2025-04-13 16:51:48 - INFO - index 11100 scraped. Results size: 111010\n",
      "2025-04-13 16:52:49 - INFO - index 11200 scraped. Results size: 112010\n",
      "2025-04-13 16:54:21 - INFO - index 11300 scraped. Results size: 113010\n"
     ]
    }
   ],
   "source": [
    "individual_running_data = pd.DataFrame()\n",
    "\n",
    "for index, row in running_data.iterrows():\n",
    "    ind_data = scraper.scrape_individual_data(MARATHON_URL + row['hyper_link'])\n",
    "    ind_data['bib_number'] = row['bib_number']\n",
    "\n",
    "    individual_running_data = pd.concat([individual_running_data, ind_data])\n",
    "\n",
    "    if index % 100 == 0:\n",
    "        logging.info(f'index {index} scraped. Results size: {individual_running_data.shape[0]}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_running_data.to_csv(INDIVIDUAL_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
